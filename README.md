# Big Data Churn Prediction withÂ PySpark

Below is a data science project involving using PySpark as one of the best big data technologies to be able to predict the churn from the event data set of one of the subscribtion model streaming services.

# Table of Contents
1. [Installation](#installation)
2. [Project Motivation](#project-motivation)
3. [File Descriptions](#file-descriptions)
4. [Results](#results)
5. [Licensing](#licensing-authors-and-acknowledgements)

# Installation
The written code doesn't require installation or specific libraries to run beyond Anaconda distribution of Python and PySpark, just the imports of modules done at the beginning of each notebook.  The code should run fine as Python 3.*

# Project Motivation
As part of the Udacity's Data Science Nano Degree, I have built several real world case scenario projects to apply the learnings and build a mini portfolio. As part of the graduation requirements, there were several capstone projects to choose from. For mine, I have chosen to deal with big data using one of the popular technologies available out there called PySpark. There might have been several reasons for my decision, with some of them are bias lol. (such as having spent several months on the UC Berkeley campus where Spark was built, and the reason that I come from a Computer Engineering background which might make me better fit than others understanding computer technicalities as apposed to working with statistics or math heavy algorithms)
In this project, the problem statement is to predict the churning of users whom use streaming service of a fictional company called "Sparkify". At Sparkify, there is a dataset totaling 12GB of event logs where a small subset of 128MB was taken to allow us work on exploring the dataset and building a model that can later be deployed on the cloud (such as AWS EMR). Identifying and analyzing churn is a common and important task for data scientist to be aware of. For a company like Sparkify to predict potentially churning users can allow them to take the effort to retain those users and therefore saving revenue which would otherwise be very difficult to generate.

# File Descriptions
This project has a note called `Sparkify.ipynb` that contained all the workings and a dataset file `mini_sparkify_event_data.json` is 128MB large and can be [found here](https://www.dropbox.com/s/kaq9jkxaghiouji/mini_sparkify_event_data.json?dl=0).

# Results
The results of this finding can be viewed on [this medium post](https://khalidalawar1.medium.com/big-data-churn-prediction-with-pyspark-339e1681c373)


